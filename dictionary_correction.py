# -*- coding: utf-8 -*-
"""Cópia de analise_enderecos_15a

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OKTh02MddQicRdgwLT4QIUuOfo90bARV
"""

import pandas as pd
import string
from unidecode import unidecode
from fuzzywuzzy import process, fuzz
from Levenshtein import distance, jaro, jaro_winkler, ratio

"""# **Importing the data**"""

from google.colab import drive
drive.mount('/content/drive/')

!mkdir -p "drive/MyDrive/analise de endereços"

enderecos_15a = pd.read_excel('/content/drive/MyDrive/analise de endereços/enderecos_processos_em_andamento_15a.xlsx', index_col=0)
enderecos_15a

enderecos_dne = pd.read_csv('/content/drive/MyDrive/analise de endereços/enderecos_dne.csv',sep=';')
enderecos_dne.columns = ['logradouro','cep','bairro','cidade']
enderecos_dne

"""# **Pre-analysis**

Before doing some analysis, we are going to treat the data, removing some special characters and standardizing strings.
"""

def normalize(v):
    '''
    Removes special characters and punctuation and makes all letters lowercase if value is a string
    '''
    if type(v) == str:
        return unidecode(v).translate(str.maketrans('', '', string.punctuation)).lower().strip()
    else:
        return v

"""## Standardizing strings"""

enderecos_15a = enderecos_15a.applymap(normalize)

enderecos_15a['logradouro'] = enderecos_15a['logradouro'].str.replace('rua','r')
enderecos_15a['logradouro'] = enderecos_15a['logradouro'].str.replace('avenida','av')

enderecos_dne = enderecos_dne.applymap(normalize)

"""# **Exploratory Analysis**

## Checking unique values of neighborhoods
"""

enderecos_15a['bairro'].value_counts()

"""there is a lenght of 455 unique values, this is a much higher than expected, showing that there are spelling errors in filling in the neighborhoods field. 

Below we can visualize the less recurring values and better check these errors.

### Visualizing the less recurring values
"""

b = enderecos_15a['bairro'].value_counts()
b[b < 5].index

"""## Types of roads

We can do the same with types of roads
"""

enderecos_15a['logradouro'].str.split(expand=True)[0].value_counts()

"""# **Levenshtein Distance Correction**

To solve this problem, we can use the Levenshtein Distance to calculate the score of similarity  with referance database.

## Corrective Function
"""

def match_names(name, list_names, min_score=0):
    return process.extractOne(name, list_names, scorer=fuzz.token_set_ratio)

"""### Neighborhood corretion

#### Replacing null values
"""

enderecos_15a['bairro'] = enderecos_15a['bairro'].fillna('none')

"""#### Creating a list of unique values"""

bairros_15a = enderecos_15a['bairro'].unique().tolist()

"""#### Creating a list of correct neighborhoods to compare"""

bairros_dne = enderecos_dne['bairro'].unique().tolist()

"""#### List with matches +80"""

names = []
lower_matches = []
for x in bairros_15a:
    match = match_names(x, bairros_dne)
    if match[1] >= 80:
        name = (str(x), str(match[0]))
        names.append(name)
    else:
      lower_match = (str(x), str(match[0]), str(match[1]))
      lower_matches.append(lower_match)
bairro_dict= names
bairro_dict

"""#### List with low matches"""

lower_matches.sort()
lower_matches

"""#### Percentage with matches +80

Now it is clear that the data is way more complicated than expected, only 59% of of the neighbohood had at last a score of 80 in Levensthein Distance. This indicates that this method is not suficient to an eficient corretion.
"""

# Porcentagem de matches +80
(len(names)/len(bairros_15a))*100

"""#### Creating a dictionary with correct values"""

# Criando um dicionário que mapeia bairros com possíveis escritas e uma lista com valores sem mapeamento.
matches_dict = dict()
bairros_desconhecidos = list()

for name, match in bairro_dict:
  if match:
    if match in matches_dict:
      matches_dict[match].append(name)
    else:
      matches_dict[match] = list()
      matches_dict[match].append(name)
  else:
    if name != 'none':
      bairros_desconhecidos.append(name)

bairros_desconhecidos
matches_dict

"""#### Including correct values to original dataframe"""

enderecos_15a['new_bairro'] = enderecos_15a['bairro'].replace(bairro_dict)
enderecos_15a